llm:
  # ðŸŸ¢ CHANGED: The most intelligent "Nano" model available
  reasoning_model: "qwen2.5:0.5b"
  base_url: "http://localhost:11434"
  # Low temperature makes it strictly logical for coding
  temperature: 0.1

embeddings:
  model_name: "nomic-embed-text"
  base_url: "http://localhost:11434"

rag:
  # Keep chunking small for low RAM
  chunk_size: 500
  chunk_overlap: 100
  vector_db_path: "data/chroma_db"
  collection_name: "sales_data"